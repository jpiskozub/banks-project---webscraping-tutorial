{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as r\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import sqlite3 as sql\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(stage):\n",
    "    with open(\"code_log.txt\", \"a\") as log_file:\n",
    "        log_file.write(f\"Progress at stage: {stage}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:52: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:52: SyntaxWarning: invalid escape sequence '\\$'\n",
      "/tmp/ipykernel_239216/3626082119.py:52: SyntaxWarning: invalid escape sequence '\\$'\n",
      "  df['Market Capitalization (USD)'] = df['Market Capitalization (USD)'].replace('[\\$,]', '', regex=True).astype(float)\n"
     ]
    }
   ],
   "source": [
    "def extract(url, table_attribs):\n",
    "    ''' This function extracts the required\n",
    "    information from the website and saves it to a dataframe. The\n",
    "    function returns the dataframe for further processing. '''\n",
    "    log_progress(\"Starting extraction\")\n",
    "    \n",
    "    # Send a GET request to the URL\n",
    "    response = r.get(url)\n",
    "    log_progress(\"Received response from URL\")\n",
    "    \n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    log_progress(\"Parsed HTML content\")\n",
    "    \n",
    "    # Find the table with the specified attributes\n",
    "    table = soup.find('table', attrs=table_attribs)\n",
    "    log_progress(\"Found the table in HTML content\")\n",
    "    \n",
    "    # Extract the table headers\n",
    "    headers = [header.text.strip() for header in table.find_all('th')]\n",
    "    \n",
    "    # Extract the table rows\n",
    "    rows = []\n",
    "    for row in table.find_all('tr')[1:]:  # Skip the header row\n",
    "        cells = row.find_all('td')\n",
    "        row_data = [cell.text.strip() for cell in cells]\n",
    "        rows.append(row_data)\n",
    "    \n",
    "    # Create a DataFrame from the extracted data\n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "    log_progress(\"Created DataFrame from extracted data\")\n",
    "    \n",
    "    log_progress(\"Extraction completed\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def transform(df, exchange_rates_path):\n",
    "    ''' This function adds columns for Market Capitalization in GBP, EUR, and INR\n",
    "    based on the exchange rate information provided in a CSV file. The function\n",
    "    returns the transformed dataframe.'''\n",
    "    log_progress(\"Starting transformation\")\n",
    "    \n",
    "    # Load exchange rates from CSV file\n",
    "    exchange_rates = pd.read_csv(exchange_rates_path)\n",
    "    \n",
    "    # Extract exchange rates\n",
    "    usd_to_gbp = exchange_rates.loc[exchange_rates['Currency'] == 'GBP', 'Rate'].values[0]\n",
    "    usd_to_eur = exchange_rates.loc[exchange_rates['Currency'] == 'EUR', 'Rate'].values[0]\n",
    "    usd_to_inr = exchange_rates.loc[exchange_rates['Currency'] == 'INR', 'Rate'].values[0]\n",
    "    \n",
    "    # Convert Market Capitalization to float\n",
    "    df['Market Capitalization (USD)'] = df['Market Capitalization (USD)'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "    \n",
    "    # Add new columns for Market Capitalization in GBP, EUR, and INR\n",
    "    df['Market Capitalization (GBP)'] = (df['Market Capitalization (USD)'] * usd_to_gbp).round(2)\n",
    "    df['Market Capitalization (EUR)'] = (df['Market Capitalization (USD)'] * usd_to_eur).round(2)\n",
    "    df['Market Capitalization (INR)'] = (df['Market Capitalization (USD)'] * usd_to_inr).round(2)\n",
    "    \n",
    "    log_progress(\"Transformation completed\")\n",
    "    return df\n",
    "\n",
    "def load_to_csv(df, csv_path):\n",
    "    ''' This function saves the final dataframe as a `CSV` file \n",
    "    in the provided path. Function returns nothing.'''\n",
    "    log_progress(\"Starting CSV load\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    log_progress(\"CSV load completed\")\n",
    "\n",
    "def load_to_db(df, sql_connection, table_name):\n",
    "    ''' This function saves the final dataframe as a database table\n",
    "    with the provided name. Function returns nothing.'''\n",
    "    log_progress(\"Starting DB load\")\n",
    "    engine = create_engine(sql_connection)\n",
    "    df.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "    log_progress(\"DB load completed\")\n",
    "    \n",
    "def run_query(query_statement, sql_connection):\n",
    "    ''' This function runs the stated query on the database table and\n",
    "    prints the output on the terminal. Function returns nothing. '''\n",
    "    log_progress(\"Starting query execution\")\n",
    "    engine = create_engine(sql_connection)\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(query_statement)\n",
    "        for row in result:\n",
    "            print(row)\n",
    "    log_progress(\"Query execution completed\")\n",
    "    \n",
    "def verify_log_entries(log_file_path):\n",
    "    ''' This function reads and prints the contents of the log file to verify the log entries. '''\n",
    "    with open(log_file_path, 'r') as log_file:\n",
    "        log_contents = log_file.read()\n",
    "        print(log_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (2207838075.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31murl = 'https://web.archive.org/web/20230908091635 /https://en.wikipedia.org/wiki/List_of_largest_banks\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "url = 'https://web.archive.org/web/20230908091635 /https://en.wikipedia.org/wiki/List_of_largest_banks'\n",
    "table_attribs = {'class': 'wikitable'}  \n",
    "exchange_rates_path = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv'  # Path to the exchange rates CSV file\n",
    "csv_path = 'Largest_banks_data.csv'\n",
    "sql_connection = 'sqlite:///Banks.db'  \n",
    "table_name = 'Largest_banks'\n",
    "query_statement = 'SELECT * FROM market_capitalization'\n",
    "log_file_path = 'code_log.txt'\n",
    "\n",
    "# Extract data\n",
    "df = extract(url, table_attribs)\n",
    "\n",
    "# Transform data\n",
    "df_transformed = transform(df, exchange_rates_path)\n",
    "\n",
    "# Load to CSV\n",
    "load_to_csv(df_transformed, csv_path)\n",
    "\n",
    "# Load to DB\n",
    "load_to_db(df_transformed, sql_connection, table_name)\n",
    "\n",
    "# Run query\n",
    "run_query(query_statement, sql_connection)\n",
    "\n",
    "# Verify log entries\n",
    "verify_log_entries(log_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WebScraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
